# ddcar_related_terms.py

import pandas as pd
import time
import requests
import re 
import os
from dotenv import load_dotenv

load_dotenv()

# Groq API è¨­å®š
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_API_KEY = os.getenv("API_KEY")

headers = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json"
}


# LLM promptï¼šæ‰¾å‡ºå“ç‰Œèˆ‡è»Šæ¬¾
def build_prompt(content):
    return f"""
ä½ æ˜¯ä¸€å€‹é›»å‹•è»Šåˆ†æåŠ©æ‰‹ã€‚æ ¹æ“šä»¥ä¸‹æ–‡ç« ï¼Œè«‹åˆ¤æ–·æ˜¯å¦æåˆ°äº†å…·é«”è»Šæ¬¾åç¨±ï¼Œä¸¦å°‡å®ƒå€‘å°æ‡‰åˆ°æ‰€å±¬å“ç‰Œï¼ˆå¦‚ Tesla çš„ Model Yï¼‰ã€‚
è«‹ç”¨ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š
å“ç‰Œå: [è»Šæ¬¾1, è»Šæ¬¾2, ...]

æ–‡ç« å…§å®¹ï¼š
---
{content}
---
è«‹æ³¨æ„ï¼šå¦‚æœæ²’æœ‰æåˆ°ä»»ä½•å…·é«”è»Šæ¬¾ï¼Œå¯ä»¥å›å‚³ç©ºå­—å…¸ï¼Œä¾‹å¦‚ï¼š{{}}ã€‚
"""

# å‘¼å« Groq API åˆ†æ
def call_groq(content, max_retries=3):
    payload = {
        "model": "llama3-70b-8192",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é›»å‹•è»Šè©•è«–åˆ†æå“¡ã€‚"},
            {"role": "user", "content": build_prompt(content)}
        ],
        "temperature": 0.3
    }

    for attempt in range(1, max_retries + 1):
        try:
            res = requests.post(GROQ_API_URL, headers=headers, json=payload, timeout=60)
            if res.status_code == 429:
                wait_time = 5 * attempt
                print(f"â³ ç¬¬ {attempt} æ¬¡ï¼š429 é™æµï¼Œç­‰å¾… {wait_time} ç§’å†è©¦...")
                time.sleep(wait_time)
                continue
            res.raise_for_status()
            return res.json()["choices"][0]["message"]["content"]
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Groq API error (å˜—è©¦ {attempt}/{max_retries}):", e)
            time.sleep(5 * attempt)
    return ""


# æ“·å–æ‰€æœ‰è»Šæ¬¾åç¨±ï¼ˆä¾†è‡ªæ¯å€‹ [] å€æ®µï¼‰
def extract_models(llm_response):
    pattern = r"\[([^\]]+)\]"
    matches = re.findall(pattern, llm_response)
    models = []
    for match in matches:
        items = [x.strip() for x in match.split(",") if x.strip()]
        models.extend(items)
    # å»é‡å¾Œæ’åº
    models = sorted(set(models))
    return "ã€".join(models) if models else ""

# è®€æª”æ¡ˆ
df = pd.read_csv("ddcar_ev_news_with_brand.csv")

llm_responses = []
car_model_tags = []

# é–‹å§‹åˆ†ææ¯ä¸€ç¯‡
for idx, row in df.iterrows():
    print(f"ğŸ” åˆ†æç¬¬ {idx+1} ç¯‡æ–‡ç« ...")
    content = str(row["æ–°èå…§æ–‡"])[:8000]  # è‹¥å…§æ–‡å¤ªé•·å¯æˆªæ–·
    llm_output = call_groq(content)
    llm_responses.append(llm_output)
    car_model_tags.append(extract_models(llm_output))
    time.sleep(5)

# åŠ æ¬„ä½
df["å“ç‰Œç›¸é—œæ¨™ç±¤ï¼ˆLLMï¼‰"] = llm_responses
df["ç›¸é—œè»Šæ¬¾åˆ—è¡¨"] = car_model_tags

# è¼¸å‡ºçµæœ
df.to_csv("ddcar_ev_news_with_tags.csv", index=False, encoding="utf-8-sig")
print("âœ… å·²å„²å­˜çµæœè‡³ ddcar_ev_news_with_tags.csv")
