import pandas as pd
import numpy as np
import faiss
import gradio as gr
import pickle
from sentence_transformers import SentenceTransformer
from groq import Groq
import sqlite3
import csv
import datetime
from pathlib import Path
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"  # é¿å…tokenizerséŒ¯èª¤

# åˆå§‹åŒ–èˆ‡è¼‰å…¥
df = pd.read_csv("faq_data.csv")  # FAQçš„åŸå§‹è³‡æ–™ï¼ˆå•é¡Œã€ç­”æ¡ˆï¼‰
with open("faq_texts.pkl", "rb") as f:
    faq_texts = pickle.load(f)  # çµåˆéçš„æ–‡å­—èªæ–™ï¼Œç”¨æ–¼æŸ¥è©¢æ¯”å°
index = faiss.read_index("faq.index")  # FAISS å»ºç«‹çš„èªæ„æŸ¥è©¢è³‡æ–™åº«
model = SentenceTransformer("BAAI/bge-large-zh")  # hugguing faceä¸Šçš„å°‡æ–‡å­—è½‰å‘é‡çš„ä¸­æ–‡èªæ„æ¨¡å‹
# åˆå§‹åŒ– Groq API
client = Groq(api_key="*********")  # ç”¨ä¾†ç™¼é€LLMè«‹æ±‚ï¼ˆGroq APIï¼‰

# åˆå§‹åŒ– SQLite è³‡æ–™åº«ï¼ˆå¦‚ä¸å­˜åœ¨å‰‡å‰µå»ºï¼‰
def init_db():
    conn = sqlite3.connect("feedback.db")
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS feedback (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        time TEXT,
        question TEXT,
        answer TEXT,
        helpful TEXT,
        report TEXT,
        topic TEXT
    )''')
    conn.commit()
    conn.close()

init_db()


# åµŒå…¥èˆ‡å›ç­”
def embed(texts):
    return model.encode(
        [f"ç‚ºé€™å¥è©±ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨æ–¼æª¢ç´¢: {t}" for t in texts],
        normalize_embeddings=True
    )

def rephrase_answer(question, original_answer, chat_history):
    system_prompt = (
    "ä½ æ˜¯äº¤é€šéƒ¨çš„ AI èªè¨€åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä»¥è‡ªç„¶ã€è¦ªåˆ‡ã€å°ˆæ¥­çš„æ–¹å¼å›è¦†æ°‘çœ¾ã€‚"
    "è«‹æ ¹æ“šä¸‹æ–¹æä¾›çš„åŸå§‹å›ç­”é€²è¡Œé‡å¯«ï¼Œä½¿å…¶æ›´æ˜“æ‡‚ã€æ›´è‡ªç„¶ã€‚"
    "åœ¨å›ç­”ä¸­ï¼Œå¦‚æœèˆ‡æ°‘çœ¾æ„è¦‹åæ˜ æˆ–å»ºè­°æœ‰é—œï¼Œè«‹å¼•å°ä»–å€‘å‰å¾€éƒ¨é•·ä¿¡ç®±ï¼šhttps://poms.motc.gov.tw/Daoan/twã€‚"
    "æ‰€æœ‰å›ç­”å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸å¾—å‡ºç¾ã€ä½¿ç”¨è€…ï¼šã€æˆ–ã€AIï¼šã€ç­‰æ ¼å¼ã€‚"
    "å¦‚æœä½ ç„¡æ³•å›ç­”å•é¡Œï¼Œè«‹èªªï¼š"
    "ã€Œå°ä¸èµ·ï¼Œæ‚¨å•çš„å•é¡Œæˆ‘ç›®å‰ç„¡æ³•å›ç­”ï¼Œè©³æƒ…è«‹æ´½äº¤é€šéƒ¨å®¢æœå°ˆç·šè©¢å•ï¼š0800-231-161ã€‚ã€"
    )


    context = "ã€‚".join([q for q, _ in chat_history[-2:]])
    user_prompt = (
        f"å•é¡ŒèƒŒæ™¯ï¼š{context}\n\n"
        f"åŸå§‹å›ç­”ï¼š{original_answer}\n\n"
        f"è«‹é‡æ–°è¡¨é”é€™æ®µå…§å®¹ï¼Œä½¿å…¶è‡ªç„¶æ˜“æ‡‚ã€‚"
    )

    response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7,
        max_tokens=512
    )

    return response.choices[0].message.content.strip()

# LLMå•é¡Œè‡ªå‹•åˆ†é¡
def classify_topic_with_llm(question):
    system_prompt = (
        "ä½ æ˜¯äº¤é€šéƒ¨çš„å…§éƒ¨å®¢æœè³‡æ–™åˆ†é¡å“¡ï¼Œè«‹å”åŠ©å°‡æ°‘çœ¾çš„å•é¡Œä¾ç…§ä¸»é¡Œåˆ†é¡ã€‚"
        "è«‹å¾ä¸‹åˆ—äº”å€‹ä¸»é¡Œä¸­é¸æ“‡æœ€ç¬¦åˆæ­¤å•é¡Œçš„åˆ†é¡ï¼š"
        "äº¤é€šé•è¦ã€å¤§çœ¾é‹è¼¸ã€é“è·¯å»ºè¨­ã€æ”¿ç­–å»ºè­°ã€å…¶ä»–ã€‚"
        "è«‹åƒ…å›è¦†é€™äº”å€‹é¡åˆ¥ä¸­çš„ä¸€å€‹ï¼Œä¸è¦åŠ ä¸Šå¤šé¤˜èªªæ˜ã€‚"
    )
    user_prompt = f"å•é¡Œå…§å®¹ï¼š{question}\nè«‹å›è¦†å°æ‡‰ä¸»é¡Œï¼š"

    response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0,
        max_tokens=20
    )
    return response.choices[0].message.content.strip()


# æŸ¥è©¢æµç¨‹
def answer_question(user_input, chat_history):
    query_vector = embed([user_input])[0].astype("float32").reshape(1, -1)
    D, I = index.search(query_vector, k=1)
    original_answer = df.iloc[I[0][0]]['ç­”è¦†']
    rewritten = rephrase_answer(user_input, original_answer, chat_history)
    chat_history.append((user_input, rewritten))
    return chat_history, chat_history, rewritten, ""

# å•ç­”å›é¥‹ç´€éŒ„
def record_feedback(chat_history, helpful, report_text):
    timestamp = datetime.datetime.now().isoformat()
    last_q, last_a = chat_history[-1]
    topic = classify_topic_with_llm(last_q)

    # å¯«å…¥ TXTï¼ˆå¯é¸ï¼‰
    log = (
        f"[{timestamp}]\n"
        f"Q: {last_q}\n"
        f"A: {last_a}\n"
        f"ğŸ‘Helpful: {helpful}\n"
        f"ğŸReport: {report_text}\n\n"
    )
    with open("feedback_log.txt", "a", encoding="utf-8") as f:
        f.write(log)

    # å¯«å…¥ CSV
    csv_file = Path("feedback_log.csv")
    file_exists = csv_file.exists()
    with open(csv_file, mode="a", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        if not file_exists:
            writer.writerow(["æ™‚é–“", "å•é¡Œ", "å›ç­”", "æ»¿æ„èˆ‡å¦", "éŒ¯èª¤è£œå……", "ä¸»é¡Œåˆ†é¡"])
        writer.writerow([timestamp, last_q, last_a, helpful, report_text, topic])

    # å¯«å…¥ SQLite
    conn = sqlite3.connect("feedback.db")
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO feedback (time, question, answer, helpful, report, topic)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (timestamp, last_q, last_a, helpful, report_text, topic))
    conn.commit()
    conn.close()

    # å›å‚³ç©ºæ­·å² â†’ é‡è¨­å¤šè¼ªå°è©±
    return [], [], "âœ… æ„Ÿè¬æ‚¨çš„å›é¥‹ï¼Œæˆ‘å€‘å·²è¨˜éŒ„ã€‚"


# UI å»ºæ§‹
with gr.Blocks() as demo:
    gr.Markdown("## äº¤é€šéƒ¨ AI å•ç­”åŠ©ç†ï¼ˆå¤šè¼ªå°è©± + å›é¥‹æ©Ÿåˆ¶ï¼‰")

    chat_state = gr.State([])

    with gr.Row():
        user_input = gr.Textbox(lines=2, label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ")
        submit_btn = gr.Button("é€å‡ºå•é¡Œ")

    chat_display = gr.Chatbot(label="å°è©±ç´€éŒ„")
    current_answer = gr.Textbox(label="ç›®å‰å›ç­”", interactive=False)

    with gr.Row():
        good_btn = gr.Button("æ»¿æ„")
        bad_btn = gr.Button("ä¸æ»¿æ„")

    report_input = gr.Textbox(label="å¦‚æœ‰éŒ¯èª¤ï¼Œå¯è£œå……èªªæ˜", lines=2)
    feedback_msg = gr.Textbox(label="ç³»çµ±è¨Šæ¯", interactive=False)

    # æ”¹æˆå¦‚éƒ­æŒ‰ä¸‹æŒ‰éˆ•ï¼Œå°±æœƒé‡æ•´èŠå¤©å®¤ï¼Œä»¥å…å•é¡Œäº’ç›¸å¹²æ“¾
    submit_btn.click(
        answer_question,
        inputs=[user_input, chat_state],
        outputs=[chat_state, chat_display, current_answer, feedback_msg]
    )

    good_btn.click(
    record_feedback,
    inputs=[chat_state, gr.Textbox(value="æ˜¯", visible=False), report_input],
    outputs=[chat_state, chat_display, feedback_msg]
    )

    bad_btn.click(
        record_feedback,
        inputs=[chat_state, gr.Textbox(value="å¦", visible=False), report_input],
        outputs=[chat_state, chat_display, feedback_msg]
    )


demo.launch()
