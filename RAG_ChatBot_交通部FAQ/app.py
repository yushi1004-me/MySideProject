import pandas as pd
import numpy as np
import faiss
import gradio as gr
import pickle
from sentence_transformers import SentenceTransformer
from groq import Groq
import datetime

# ---------- è¼‰å…¥è³‡æº ----------
df = pd.read_csv("faq_data.csv")
with open("faq_texts.pkl", "rb") as f:
    faq_texts = pickle.load(f)

index = faiss.read_index("faq.index")
model = SentenceTransformer("BAAI/bge-large-zh")
# åˆå§‹åŒ– Groq API
client = Groq(api_key="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")


# ---------- åµŒå…¥èˆ‡å›ç­” ----------
def embed(texts):
    return model.encode(
        [f"ç‚ºé€™å¥è©±ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨æ–¼æª¢ç´¢: {t}" for t in texts],
        normalize_embeddings=True
    )

def rephrase_answer(question, original_answer, chat_history):
    context = "ã€‚".join([q for q, _ in chat_history[-2:]])  # å–æœ€è¿‘å¹¾è¼ªå•é¡Œä½œç‚ºèªå¢ƒ
    system_prompt = (
        "ä½ æ˜¯äº¤é€šéƒ¨çš„ AI èªè¨€åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œç”¨è‡ªç„¶ã€è¦ªåˆ‡ã€å°ˆæ¥­çš„èªæ°£å›ç­”æ°‘çœ¾çš„å•é¡Œã€‚"
        "è«‹æ ¹æ“šä¸‹æ–¹æä¾›çš„åŸå§‹å›ç­”é€²è¡Œé‡å¯«ï¼Œä½¿å…¶æ›´æ˜“æ‡‚ã€æ›´è‡ªç„¶ã€‚"
        "ä¸è¦å‡ºç¾ã€ä½¿ç”¨è€…ï¼šã€æˆ–ã€AIï¼šã€ç­‰æ¨™ç±¤ï¼Œä¹Ÿä¸éœ€è¦æ¨¡ä»¿å°è©±æ ¼å¼ã€‚"
        "å¦‚æœä½ ç„¡æ³•å›ç­”å•é¡Œï¼Œè«‹ä½¿ç”¨é€™å¥è©±ä½œç‚ºå›æ‡‰ï¼š"
        "'å°ä¸èµ·ï¼Œæ‚¨å•çš„å•é¡Œæˆ‘ç›®å‰ç„¡æ³•å›ç­”ï¼Œè©³æƒ…è«‹æ´½äº¤é€šéƒ¨å®¢æœå°ˆç·šè©¢å•ï¼š0800-231-161ã€‚'"
    )

    user_prompt = (
        f"å•é¡ŒèƒŒæ™¯ï¼ˆè¿‘å¹¾è¼ªæå•æ‘˜è¦ï¼‰: {context}\n\n"
        f"é€™æ˜¯åŸå§‹å›ç­”ï¼š{original_answer}\n\n"
        f"è«‹ç”¨ç¹é«”ä¸­æ–‡ã€è‡ªç„¶èªæ°£é‡æ–°èªªæ˜é€™æ®µå›ç­”ã€‚"
    )

    response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7,
        max_tokens=512
    )

    return response.choices[0].message.content.strip()

# ---------- æŸ¥è©¢ä¸»æµç¨‹ ----------
def answer_question(user_input, chat_history):
    query_vector = embed([user_input])[0].astype("float32").reshape(1, -1)
    D, I = index.search(query_vector, k=1)
    original_answer = df.iloc[I[0][0]]['ç­”è¦†']
    rewritten = rephrase_answer(user_input, original_answer, chat_history)
    chat_history.append((user_input, rewritten))
    return chat_history, chat_history, rewritten, ""

# ---------- å›é¥‹æŒ‰éˆ• ----------
def record_feedback(chat_history, helpful, report):
    timestamp = datetime.datetime.now().isoformat()
    last_q, last_a = chat_history[-1]
    with open("feedback_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}]\nQ: {last_q}\nA: {last_a}\nğŸ‘Helpful: {helpful}\nğŸReport: {report}\n\n")
    return "âœ… æ„Ÿè¬æ‚¨çš„å›é¥‹ï¼Œå·²è¨˜éŒ„ï¼"

# ---------- Gradio ä»‹é¢ ----------
with gr.Blocks() as demo:
    gr.Markdown("### äº¤é€šéƒ¨ AI å•ç­”åŠ©ç†ï¼ˆå¤šè¼ªå°è©± + å›é¥‹ï¼‰")

    chat_state = gr.State([])

    with gr.Row():
        user_input = gr.Textbox(label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ", lines=2)
        submit_btn = gr.Button("é€å‡ºå•é¡Œ")

    chat_display = gr.Chatbot(label="å°è©±ç´€éŒ„")
    current_answer = gr.Textbox(label="ç›®å‰å›è¦†", interactive=False)

    with gr.Row():
        good_btn = gr.Button("ğŸ‘ æ»¿æ„")
        bad_btn = gr.Button("ğŸ‘ ä¸æ»¿æ„")

    error_report = gr.Textbox(label="å¦‚éœ€è£œå……èªªæ˜éŒ¯èª¤ï¼Œå¯åœ¨æ­¤å¡«å¯«", lines=2)
    feedback_msg = gr.Textbox(label="ç³»çµ±è¨Šæ¯", interactive=False)

    submit_btn.click(
        answer_question,
        inputs=[user_input, chat_state],
        outputs=[chat_state, chat_display, current_answer, feedback_msg]
    )

    good_btn.click(
        record_feedback,
        inputs=[chat_state, gr.Textbox(value="æ˜¯", visible=False), error_report],
        outputs=[feedback_msg]
    )

    bad_btn.click(
        record_feedback,
        inputs=[chat_state, gr.Textbox(value="å¦", visible=False), error_report],
        outputs=[feedback_msg]
    )

demo.launch()